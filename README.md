
# <p align=center>`Awesome Geoscience Foundation Models`</p>

:star2:**A collection of papers for Geoscience Foundation Models (GFMs) in our paper "[When Geoscience Meets Foundation Models: Towards General Geoscience Artificial Intelligence System](https://doi.org/10.1109/MGRS.2024.3496478)".**

## Note
For detailed analysis of these models, please ref to the accepted paper now available on [Arxiv](https://arxiv.org/abs/2309.06799), and it will be available on [IEEE Xplore](https://doi.org/10.1109/MGRS.2024.3496478) soon.

## Citation

If you find this repository useful, please consider giving a star :star: and citation:

```
@article{zhang2024when,
  title = {When Geoscience Meets Foundation Models: Towards General Geoscience Artificial Intelligence System},
  journal = {IEEE Geoscience and Remote Sensing Magazine},
  author = {Zhang, Hao and Xu, Jin-Jian and Cui, Hong-Wei and Li, Lin and Yang, Yaowen and Tang, Chao-Sheng and Boers, Niklas},
  year = {2024},
  doi={10.1109/MGRS.2024.3496478},
  arxiv={2309.06799}
}
```

## Related surveys and reviews
|Year|Title|Publication|Paper|
|:---:|---|:---:|:---:|
|2023|Brain-inspired remote sensing foundation models and open problems: A comprehensive survey|IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing|[link](https://ieeexplore.ieee.org/abstract/document/10254282/)|
|2023|Large Remote Sensing Model: Progress and Prospects|Geomatics and Information Science of Wuhan University|[link](http://ch.whu.edu.cn/en/article/doi/10.13203/j.whugis20230341)|
|2024|Towards Urban General Intelligence: A Review and Outlook of Urban Foundation Models|arXiv preprint arXiv:2402.01749|[link](https://arxiv.org/abs/2402.01749)|
|2024|Vision-language models in remote sensing: Current progress and future trends|IEEE Geoscience and Remote Sensing Magazine|[link](https://ieeexplore.ieee.org/abstract/document/10506064/)|
|2024|When geoscience meets generative AI and large language models: Foundations, trends, and future challenges|Expert Systems|[link](https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13654)|
|2024|Foundation Models for Geophysics: Reviews and Perspectives|arXiv preprint arXiv:2406.03163|[link](https://arxiv.org/abs/2406.03163)|
|2024|Towards Vision-Language Geo-Foundation Model: A Survey|arXiv preprint arXiv:2406.09385|[link](https://arxiv.org/abs/2406.09385)|
|2024|A systematic review of geospatial location embedding approaches in large language models: A path to spatial AI systems|arXiv preprint arXiv:2401.10279|[link](https://arxiv.org/abs/2401.10279)|


## Advanced Large Language Models for Geoscience
|Year|Title|Publication|Paper|
|:---:|---|:---:|:---:|
|2021|Geoscience Language Processing for Exploration|Abu Dhabi International Petroleum Exhibition and Conference|[link](https://onepetro.org/SPEADIP/proceedings-abstract/21ADIP/3-21ADIP/474196)|
|2022|Language Model for Earth Science: Exploring Potential Downstream Applications as well as Current Challenges|IGARSS 2022-2022 IEEE International Geoscience and Remote Sensing Symposium|[link](https://ieeexplore.ieee.org/abstract/document/9883682/)|
|2019|SciBERT: A pretrained language model for scientific text|arXiv preprint arXiv:1903.10676|[link](https://arxiv.org/abs/1903.10676)|
|2023|Learning A Foundation Language Model for Geoscience Knowledge Understanding and Utilization|arXiv preprint arXiv:2306.05064|[link](https://dl.acm.org/doi/abs/10.1145/3616855.3635772)|
|2023|CnGeoPLM: Contextual knowledge selection and embedding with pretrained language representation model for the geoscience domain|Earth Science Informatics|[link](https://link.springer.com/article/10.1007/s12145-023-01112-6)|
|2022|GeoBERTSegmenter: Word segmentation of Chinese texts in the geoscience domain using the improved BERT model|Earth and Space Science|[link](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2022EA002511)|
|2023|Oceangpt: A large language model for ocean science tasks|arXiv preprint arXiv:2310.02031|[link](https://arxiv.org/abs/2310.02031)|
|2022|Geoscience language models and their intrinsic evaluation|Applied Computing and Geosciences|[link](https://www.sciencedirect.com/science/article/pii/S2590197422000064)|
|2023|Applications of Natural Language Processing to Geoscience Text Data and Prospectivity Modeling|Natural Resources Research|[link](https://link.springer.com/article/10.1007/s11053-023-10216-1)|
|2023|Geogalactica: A scientific large language model in geoscience|arXiv preprint arXiv:2401.00434|[link](https://arxiv.org/abs/2401.00434)|
|2023|GPT4GEO: How a Language Model Sees the World's Geography|arXiv preprint arXiv:2306.00020|[link](https://arxiv.org/abs/2306.00020)|
article
|2023|Evaluating the effectiveness of large language models in representing textual descriptions of geometry and spatial relations|arXiv preprint arXiv:2307.03678|[link](https://arxiv.org/abs/2307.03678)|
|2023|Are large language models geospatially knowledgeable?|Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems|[link](https://dl.acm.org/doi/abs/10.1145/3589132.3625625)|
|2023|Towards understanding the geospatial skills of chatgpt: Taking a geographic information systems (gis) exam|Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery|[link](https://dl.acm.org/doi/abs/10.1145/3615886.3627745)|
|2023|On the opportunities and challenges of foundation models for geospatial artificial intelligence|arXiv preprint arXiv:2304.06798|[link](https://arxiv.org/abs/2304.06798)|
|2023|GeoGPT: understanding and processing geospatial tasks through an autonomous GPT|arXiv preprint arXiv:2307.07930|[link](https://arxiv.org/abs/2307.07930)|
|2024|BB-GeoGPT: A framework for learning a large language model for geographic information science|Information Processing \& Management|[link](https://www.sciencedirect.com/science/article/pii/S0306457324001675)|
|2023|Geollm: Extracting geospatial knowledge from large language models|arXiv preprint arXiv:2310.06213|[link](https://arxiv.org/abs/2310.06213)|
|2024|GeoLLM-Engine: A Realistic Environment for Building Geospatial Copilots|Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition|[link](https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Singh_GeoLLM-Engine_A_Realistic_Environment_for_Building_Geospatial_Copilots_CVPRW_2024_paper.html)|
|2024|Building a Large Language Model based Seismic Data Processing Assistant|85th EAGE Annual Conference \& Exhibition (including the Workshop Programme)|[link](https://www.earthdoc.org/content/papers/10.3997/2214-4609.202410350)|
|2024|Geoscience Knowledge Understanding and Utilization via Data-centric Large Language Model|Copernicus Meetings|[link](https://meetingorganizer.copernicus.org/EGU24/EGU24-6431.html)|
|2024|Geo-RAG: Gaining Insights from Unstructured Geological Documents with Large Language Models|Fourth EAGE Digitalization Conference \& Exhibition|[link](https://www.earthdoc.org/content/papers/10.3997/2214-4609.202439068)|


## Advanced Large Vision Models for Geoscience
|Year|Title|Publication|Paper|
|:---:|---|:---:|:---:|
|2022|RingMo: A remote sensing foundation model with masked image modeling|IEEE Transactions on Geoscience and Remote Sensing|[link](https://ieeexplore.ieee.org/abstract/document/9844015/)|
|2022|Advancing plain vision transformer toward remote sensing foundation model|IEEE Transactions on Geoscience and Remote Sensing|[link](https://ieeexplore.ieee.org/abstract/document/9956816/)|
|2023|A billion-scale foundation model for remote sensing images|arXiv preprint arXiv:2304.05215|[link](https://arxiv.org/abs/2304.05215)|
|2023|RingMo-sense: Remote sensing foundation model for spatiotemporal prediction via spatiotemporal evolution disentangling|IEEE Transactions on Geoscience and Remote Sensing|[link](https://ieeexplore.ieee.org/abstract/document/10254320/)|
|2024|RingMo-lite: A Remote Sensing Lightweight Network with CNN-Transformer Hybrid Framework|IEEE Transactions on Geoscience and Remote Sensing|[link](https://ieeexplore.ieee.org/abstract/document/10424413/)|
|2023|RingMo-SAM: A Foundation Model for Segment Anything in Multimodal Remote-Sensing Images|IEEE Transactions on Geoscience and Remote Sensing|[link](https://ieeexplore.ieee.org/abstract/document/10315957/)|
|2023|SAMRS: Scaling-up Remote Sensing Segmentation Dataset with Segment Anything Model|Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track|[link](https://proceedings.neurips.cc/paper_files/paper/2023/hash/1be3843e534ee06d3a70c7f62b983b31-Abstract-Datasets_and_Benchmarks.html)|
|2024|RSPrompter: Learning to prompt for remote sensing instance segmentation based on visual foundation model|IEEE Transactions on Geoscience and Remote Sensing|[link](https://ieeexplore.ieee.org/abstract/document/10409216/)|
|2023|SAM-Assisted Remote Sensing Imagery Semantic Segmentation with Object and Boundary Constraints|arXiv preprint arXiv:2312.02464|[link](https://ieeexplore.ieee.org/abstract/document/10636322/)|
|2023|GeoSAM: Fine-tuning SAM with sparse and dense visual prompting for automated segmentation of mobility infrastructure|arXiv preprint arXiv:2311.11319|[link](https://arxiv.org/abs/2311.11319)|
|2024|One for All: Toward Unified Foundation Models for Earth Vision|arXiv preprint arXiv:2401.07527|[link](https://arxiv.org/abs/2401.07527)|
|2023|CSP: Self-Supervised Contrastive Spatial Pre-Training for Geospatial-Visual Representations|arXiv preprint arXiv:2305.01118|[link](https://proceedings.mlr.press/v202/mai23a.html)|
|2023|Foundation Models for Generalist Geospatial Artificial Intelligence|arXiv preprint arXiv:2310.18660|[link]()|
|2023|ClimaX: A foundation model for weather and climate|arXiv preprint arXiv:2301.10343|[link](https://arxiv.org/abs/2301.10343)|
|2023|W-MAE: Pre-trained weather model with masked autoencoder for multi-variable weather forecasting|arXiv preprint arXiv:2304.08754|[link](https://arxiv.org/abs/2304.08754)|
|2023|Fourcastnet: Accelerating global high-resolution weather forecasting using adaptive fourier neural operators|Proceedings of the Platform for Advanced Scientific Computing Conference|[link](https://dl.acm.org/doi/abs/10.1145/3592979.3593412)|
|2022|GraphCast: Learning skillful medium-range global weather forecasting|arXiv preprint arXiv:2212.12794|[link](https://arxiv.org/abs/2212.12794)|
|2023|FengWu: Pushing the Skillful Global Medium-range Weather Forecast beyond 10 Days Lead|arXiv preprint arXiv:2304.02948|[link](https://arxiv.org/abs/2304.02948)|
|2023|Accurate medium-range global weather forecasting with 3D neural networks|Nature|[link](https://www.nature.com/articles/s41586-023-06185-3)|
|2023|Skysense: A multi-modal remote sensing foundation model towards universal interpretation for earth observation imagery|arXiv preprint arXiv:2312.10115|[link](https://openaccess.thecvf.com/content/CVPR2024/html/Guo_SkySense_A_Multi-Modal_Remote_Sensing_Foundation_Model_Towards_Universal_Interpretation_CVPR_2024_paper.html)|
|2023|Semantic segmentation of glaciological features across multiple remote sensing platforms with the Segment Anything Model (SAM)|Journal of Glaciology|[link](https://www.cambridge.org/core/journals/journal-of-glaciology/article/semantic-segmentation-of-glaciological-features-across-multiple-remote-sensing-platforms-with-the-segment-anything-model-sam/66D3A237ACB0975C9EE9BE19E0C2564E)|
|2023|Segment anything in glaciology: An initial study implementing the segment anything model (SAM)||[link](https://www.researchsquare.com/article/rs-3011246/latest)|
|2023|Knowledge distillation with segment anything (sam) model for planetary geological mapping|International Conference on Machine Learning, Optimization, and Data Science|[link](https://link.springer.com/chapter/10.1007/978-3-031-53969-5_6)|
|2023|The segment anything model (sam) for remote sensing applications: From zero to one shot|International Journal of Applied Earth Observation and Geoinformation|[link](https://www.sciencedirect.com/science/article/pii/S1569843223003643)|
|2024|Enhancing Crop Mapping through Automated Sample Generation Based on Segment Anything Model with Medium-Resolution Satellite Imagery|Remote Sensing|[link](https://www.mdpi.com/2072-4292/16/9/1505)|
|2024|RSBuilding: Towards General Remote Sensing Image Building Extraction and Change Detection with Foundation Model|arXiv preprint arXiv:2403.07564|[link](https://arxiv.org/abs/2403.07564)|
|2024|Vision Foundation Model Guided Multi-Modal Fusion Network for Remote Sensing Semantic Segmentation|Available at SSRN 4876040|[link](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4876040)|
|2022|SatViT: Pretraining Transformers for Earth Observation|IEEE Geoscience and Remote Sensing Letters|[link](https://ieeexplore.ieee.org/abstract/document/9866058/)|
|2024|SpectralGPT: Spectral remote sensing foundation model|IEEE Transactions on Pattern Analysis and Machine Intelligence|[link](https://ieeexplore.ieee.org/abstract/document/10490262/)|
|2024|Rsmamba: Remote sensing image classification with state space model|IEEE Geoscience and Remote Sensing Letters|[link](https://ieeexplore.ieee.org/abstract/document/10542538/)|
|2024|Segment anything, from space?|Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision|[link](https://openaccess.thecvf.com/content/WACV2024/html/Ren_Segment_Anything_From_Space_WACV_2024_paper.html)|
|2024|DF4LCZ: A SAM-Empowered Data Fusion Framework for Scene-Level Local Climate Zone Classification|IEEE Transactions on Geoscience and Remote Sensing|[link](https://ieeexplore.ieee.org/abstract/document/10556641/)|
|2024|A Multispectral Automated Transfer Technique (MATT) for machine-driven image labeling utilizing the Segment Anything Model (SAM)|arXiv preprint arXiv:2402.11413|[link](https://arxiv.org/abs/2402.11413)|
|2024|S2MAE: A Spatial-Spectral Pretraining Foundation Model for Spectral Remote Sensing Data|Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition|[link](https://openaccess.thecvf.com/content/CVPR2024/html/Li_S2MAE_A_Spatial-Spectral_Pretraining_Foundation_Model_for_Spectral_Remote_Sensing_CVPR_2024_paper.html)|
|2023|A self-supervised cross-modal remote sensing foundation model with multi-domain representation and cross-domain fusion|IGARSS 2023-2023 IEEE International Geoscience and Remote Sensing Symposium|[link](https://ieeexplore.ieee.org/abstract/document/10282433/)|


## Advanced Large Vision-Language Models for Geoscience
|Year|Title|Publication|Paper|
|:---:|---|:---:|:---:|
|2022|Language transformers for remote sensing visual question answering|IGARSS 2022-2022 IEEE International Geoscience and Remote Sensing Symposium|[link](https://ieeexplore.ieee.org/abstract/document/9884036/)|
|2023|LiT-4-RSVQA: Lightweight transformer-based visual question answering in remote sensing|IGARSS 2023-2023 IEEE International Geoscience and Remote Sensing Symposium|[link](https://ieeexplore.ieee.org/abstract/document/10281674/)|
|2023|The curse of language biases in remote sensing VQA: the role of spatial attributes, language diversity, and the need for clear evaluation|arXiv preprint arXiv:2311.16782|[link](https://arxiv.org/abs/2311.16782)|
|2023|Geochat: Grounded large vision-language model for remote sensing|arXiv preprint arXiv:2311.15826|[link](https://openaccess.thecvf.com/content/CVPR2024/html/Kuckreja_GeoChat_Grounded_Large_Vision-Language_Model_for_Remote_Sensing_CVPR_2024_paper.html)|
|2024|Earthgpt: A universal multi-modal large language model for multi-sensor image comprehension in remote sensing domain|arXiv preprint arXiv:2401.16822|[link](https://ieeexplore.ieee.org/abstract/document/10547418/)|
|2024|Skyeyegpt: Unifying remote sensing vision-language tasks via instruction tuning with large language model|arXiv preprint arXiv:2401.09712|[link](https://arxiv.org/abs/2401.09712)|
|2024|Skyscript: A large and semantically diverse vision-language dataset for remote sensing|Proceedings of the AAAI Conference on Artificial Intelligence|[link](https://ojs.aaai.org/index.php/AAAI/article/view/28393)|
|2023|Remote sensing vision-language foundation models without annotations via ground remote alignment|arXiv preprint arXiv:2312.06960|[link](https://arxiv.org/abs/2312.06960)|
|2023|Rs-clip: Zero shot remote sensing scene classification via contrastive vision-language supervision|International Journal of Applied Earth Observation and Geoinformation|[link](https://www.sciencedirect.com/science/article/pii/S1569843223003217)|
|2024|Good at captioning, bad at counting: Benchmarking GPT-4V on Earth observation data|arXiv preprint arXiv:2401.17600|[link](https://arxiv.org/abs/2401.17600)|
|2023|Rsgpt: A remote sensing vision language model and benchmark|arXiv preprint arXiv:2307.15266|[link](https://arxiv.org/abs/2307.15266)|
|2024|Chatearthnet: A global-scale, high-quality image-text dataset for remote sensing|arXiv preprint arXiv:2402.11325|[link](https://arxiv.org/abs/2402.11325)|
|2024|RS-GPT4V: A Unified Multimodal Instruction-Following Dataset for Remote Sensing Image Understanding|arXiv preprint arXiv:2406.12479|[link](https://arxiv.org/abs/2406.12479)|
|2024|Remoteclip: A vision language foundation model for remote sensing|IEEE Transactions on Geoscience and Remote Sensing|[link](https://ieeexplore.ieee.org/abstract/document/10504785/)|
|2022|CLIP-RS: A Cross-modal Remote Sensing Image Retrieval Based on CLIP, a Northern Virginia Case Study||[link](https://vtechworks.lib.vt.edu/items/beb6f813-0cc6-4594-a4ef-0068cc16b0bd)|
|2024|H2RSVLM: Towards Helpful and Honest Remote Sensing Large Vision Language Model|arXiv preprint arXiv:2403.20213|[link](https://arxiv.org/abs/2403.20213)|
|2023|Vision-Language Models for Zero-Shot Classification of Remote Sensing Images|Applied Sciences|[link](https://www.mdpi.com/2076-3417/13/22/12462)|
|2024|VRSBench: A Versatile Vision-Language Benchmark Dataset for Remote Sensing Image Understanding|arXiv preprint arXiv:2406.12384|[link](https://arxiv.org/abs/2406.12384)|
|2023|Foundation model-based multimodal remote sensing data classification|IEEE Transactions on Geoscience and Remote Sensing|[link](https://ieeexplore.ieee.org/abstract/document/10375372/)|
|2022|Prompt-RSVQA: Prompting visual context to a language model for remote sensing visual question answering|Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition|[link](http://openaccess.thecvf.com/content/CVPR2022W/EarthVision/html/Chappuis_Prompt-RSVQA_Prompting_Visual_Context_to_a_Language_Model_for_Remote_CVPRW_2022_paper.html)|
|2024|Large language models for captioning and retrieving remote sensing images|arXiv preprint arXiv:2402.06475|[link](https://arxiv.org/abs/2402.06475)|
|2023|Text2seg: Remote sensing image semantic segmentation via text-guided visual foundation models|arXiv preprint arXiv:2304.10597|[link](https://arxiv.org/abs/2304.10597)|
